{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"Runner.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PX_I15Hgcel_","colab_type":"code","outputId":"83f60ca2-06b5-42ea-e35c-971fe93544dd","executionInfo":{"status":"ok","timestamp":1567460757762,"user_tz":240,"elapsed":88922,"user":{"displayName":"Matthew Dalton","photoUrl":"","userId":"01363226145794917632"}},"colab":{"base_uri":"https://localhost:8080/","height":768}},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","project_dir = os.path.join('drive','My Drive','Personal Projects','Sleep Apnea Study','apnea-study')\n","os.chdir(project_dir)\n","!git pull\n","!pip install -r colab_requirements.txt "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","Already up to date.\n","Collecting pyEDFlib==0.1.14 (from -r colab_requirements.txt (line 1))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/c1/11d90aa4d20a1d3df04ea9e1db4e03fea4b199a5b515a057cbe5e35769c0/pyEDFlib-0.1.14.tar.gz (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 2.9MB/s \n","\u001b[?25hCollecting tensorflow-gpu==2.0.0-rc0 (from -r colab_requirements.txt (line 2))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/12/8c64cc62149cc21c70c55018502831bbf4d42bd62bed196df7de6830d21b/tensorflow_gpu-2.0.0rc0-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n","\u001b[K     |████████████████████████████████| 380.5MB 60kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from pyEDFlib==0.1.14->-r colab_requirements.txt (line 1)) (1.16.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (1.1.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (0.2.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (1.12.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (1.11.2)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (0.1.7)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (1.0.8)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (3.0.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (0.7.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (0.8.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (3.7.1)\n","Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806 (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n","\u001b[K     |████████████████████████████████| 4.3MB 30.8MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (1.15.0)\n","Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n","\u001b[K     |████████████████████████████████| 501kB 40.5MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (0.33.6)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (1.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (2.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (41.2.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (0.15.5)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc0->-r colab_requirements.txt (line 2)) (3.1.1)\n","Building wheels for collected packages: pyEDFlib\n","  Building wheel for pyEDFlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyEDFlib: filename=pyEDFlib-0.1.14-cp36-cp36m-linux_x86_64.whl size=920344 sha256=a077405c54ea8486e17efe40bbaeb1699fbc1c3044db7f16c3953b004bfb34ce\n","  Stored in directory: /root/.cache/pip/wheels/6a/62/a0/3d06c48411a5f8e18a7d7376243b81520af87cbd6f24d21cfd\n","Successfully built pyEDFlib\n","Installing collected packages: pyEDFlib, tb-nightly, tf-estimator-nightly, tensorflow-gpu\n","Successfully installed pyEDFlib-0.1.14 tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc0 tf-estimator-nightly-1.14.0.dev2019080601\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_ZGeTbBppyaa","colab_type":"text"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"NLbsnWc3cemK","colab_type":"code","colab":{}},"source":["\n","\n","import datetime\n","\n","import tensorflow as tf\n","\n","import lib.utils as utils\n","from lib.models import BaseRNN, BaseLSTM, DoubleLSTM\n","from lib.train import train, evaluate"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m17dwxeKcemO","colab_type":"text"},"source":["### Load Raw Data"]},{"cell_type":"code","metadata":{"id":"2X27UWAbcemP","colab_type":"code","colab":{}},"source":["#create_tfrecords_from_raw_data(raw_data_dir='data/raw_data',tf_rec_data_dir='data/processed_data')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wp-PtlsFcemS","colab_type":"text"},"source":["### Inputs and Parameters"]},{"cell_type":"code","metadata":{"id":"yVFvBEVBcemW","colab_type":"code","colab":{}},"source":["current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","session_name = 'small_stride_test' +  '_' + current_time\n","optimizer_params = {'learning_rate':0.0001}\n","training_params = {'num_epochs':200, 'batch_size':256,'apnea_weight':5}\n","preprocess_params = {'featurize_func' : utils.featurize_2,'seq_len':60,'pulse_sample_rate':16,'data_stride':5}\n","preprocess_func = utils.preprocess_data\n","model_params = {'rnn_hidden_dim':20}\n","test_split = .15\n","val_split = 0.1765\n","\n","\n","with tf.device(\"gpu:0\"):\n","    model = BaseLSTM(rnn_hidden_dim=model_params['rnn_hidden_dim'])\n","    loss_object = tf.keras.losses.BinaryCrossentropy()\n","    optimizer = tf.keras.optimizers.Adam(optimizer_params['learning_rate'])\n","\n","\n","log_dir = 'logs/gradient_tape/' + session_name\n","model_weights_dir = 'model_weights/' + session_name"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GahcJ_BK88JY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2EVciCD9AtN","colab_type":"code","colab":{}},"source":["dataset = utils.load_tfrecords(tf_rec_data_dir='data/processed_data')\n","\n","\n","a = preprocess_func(dataset.take(2), \n","                                 featurize_func = preprocess_params['featurize_func'],\n","                                 seq_len=preprocess_params['seq_len'], \n","                                 pulse_sample_rate=preprocess_params['pulse_sample_rate'],\n","                                 data_stride=preprocess_params['data_stride'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RSCpdDeS9ikf","colab_type":"code","outputId":"7f83fb5c-e95e-4824-d8f2-76af8ab364f1","executionInfo":{"status":"ok","timestamp":1567461115224,"user_tz":240,"elapsed":2810,"user":{"displayName":"Matthew Dalton","photoUrl":"","userId":"01363226145794917632"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["a._tensors[0].shape[0] / 3600"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.6966666666666668"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"yUCBOejicemY","colab_type":"text"},"source":["### Preprocessing and Training"]},{"cell_type":"code","metadata":{"id":"JDUHx6dtcemZ","colab_type":"code","outputId":"f956e7cd-3822-4c2c-eaec-3c64fab7bdad","executionInfo":{"status":"ok","timestamp":1567438721322,"user_tz":240,"elapsed":215240,"user":{"displayName":"Matthew Dalton","photoUrl":"","userId":"01363226145794917632"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["\n","dataset = utils.load_tfrecords(tf_rec_data_dir='data/processed_data')\n","num_records = 0\n","for i in dataset:\n","    num_records += 1\n","\n","train_data, test_data = utils.split_dataset(dataset, test_split)\n","train_data, val_data = utils.split_dataset(train_data, val_split)\n","with tf.device(\"gpu:0\"):\n","\n","    train_data = preprocess_func(train_data, \n","                                 featurize_func = preprocess_params['featurize_func'],\n","                                 seq_len=preprocess_params['seq_len'], \n","                                 pulse_sample_rate=preprocess_params['pulse_sample_rate'],\n","                                 data_stride=preprocess_params['data_stride'])\n","    val_data = preprocess_func(val_data, \n","                               featurize_func = preprocess_params['featurize_func'],\n","                               seq_len=preprocess_params['seq_len'], \n","                               pulse_sample_rate=preprocess_params['pulse_sample_rate'],\n","                               data_stride=preprocess_params['seq_len'])\n","    test_data = preprocess_func(test_data, \n","                                featurize_func = preprocess_params['featurize_func'],\n","                                seq_len=preprocess_params['seq_len'], \n","                                pulse_sample_rate=preprocess_params['pulse_sample_rate'],\n","                                data_stride=preprocess_params['seq_len'])\n","\n","train_num = train_data._tensors[0].shape[0]\n","train_bal = train_data._tensors[1].numpy().mean()\n","val_num = val_data._tensors[0].shape[0]\n","val_bal = val_data._tensors[1].numpy().mean()\n","test_num = test_data._tensors[0].shape[0]\n","test_bal = test_data._tensors[1].numpy().mean()\n","\n","data_bal = {'train':train_bal,'val':val_bal,'test':test_bal}\n","data_size = {'train':train_num,'val':val_num,'test':test_num}\n","print(train_num)\n","print(train_bal)\n","print(val_num)\n","print(val_bal)\n","print(test_num)\n","print(test_bal)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0902 15:35:26.737979 139819408115584 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["164290\n","0.09518463\n","3054\n","0.09882668\n","3170\n","0.053222924\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bFMi_bwkp8X5","colab_type":"code","outputId":"d7b814e9-c050-4a7d-e4a9-b1ab13e55731","executionInfo":{"status":"ok","timestamp":1567452399355,"user_tz":240,"elapsed":870,"user":{"displayName":"Matthew Dalton","photoUrl":"","userId":"01363226145794917632"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["%load_ext tensorboard\n","print(tf.test.is_gpu_available())\n","%tensorboard --logdir logs"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n","True\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["Reusing TensorBoard on port 6006 (pid 3267), started 0:00:07 ago. (Use '!kill 3267' to kill it.)"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div id=\"root\"></div>\n","    <script>\n","      (function() {\n","        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n","        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n","        document.querySelector(\"base\").href = \"https://localhost:6006\";\n","        function fixUpTensorboard(root) {\n","          const tftb = root.querySelector(\"tf-tensorboard\");\n","          // Disable the fragment manipulation behavior in Colab. Not\n","          // only is the behavior not useful (as the iframe's location\n","          // is not visible to the user), it causes TensorBoard's usage\n","          // of `window.replace` to navigate away from the page and to\n","          // the `localhost:<port>` URL specified by the base URI, which\n","          // in turn causes the frame to (likely) crash.\n","          tftb.removeAttribute(\"use-hash\");\n","        }\n","        function executeAllScripts(root) {\n","          // When `script` elements are inserted into the DOM by\n","          // assigning to an element's `innerHTML`, the scripts are not\n","          // executed. Thus, we manually re-insert these scripts so that\n","          // TensorBoard can initialize itself.\n","          for (const script of root.querySelectorAll(\"script\")) {\n","            const newScript = document.createElement(\"script\");\n","            newScript.type = script.type;\n","            newScript.textContent = script.textContent;\n","            root.appendChild(newScript);\n","            script.remove();\n","          }\n","        }\n","        function setHeight(root, height) {\n","          // We set the height dynamically after the TensorBoard UI has\n","          // been initialized. This avoids an intermediate state in\n","          // which the container plus the UI become taller than the\n","          // final width and cause the Colab output frame to be\n","          // permanently resized, eventually leading to an empty\n","          // vertical gap below the TensorBoard UI. It's not clear\n","          // exactly what causes this problematic intermediate state,\n","          // but setting the height late seems to fix it.\n","          root.style.height = `${height}px`;\n","        }\n","        const root = document.getElementById(\"root\");\n","        fetch(\".\")\n","          .then((x) => x.text())\n","          .then((html) => void (root.innerHTML = html))\n","          .then(() => fixUpTensorboard(root))\n","          .then(() => executeAllScripts(root))\n","          .then(() => setHeight(root, 800));\n","      })();\n","    </script>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"pbNa9N0Scemc","colab_type":"code","outputId":"a3726271-3d24-4fcf-fbe5-7ade2797d7e5","executionInfo":{"status":"error","timestamp":1567452379605,"user_tz":240,"elapsed":13561849,"user":{"displayName":"Matthew Dalton","photoUrl":"","userId":"01363226145794917632"}},"colab":{"base_uri":"https://localhost:8080/","height":412}},"source":["with tf.device(\"gpu:0\"):\n","\n","    train(model, train_data,val_data, loss_object, optimizer, log_dir,model_weights_dir,\n","          num_epochs=training_params['num_epochs'], \n","          batch_size=training_params['batch_size'],\n","          apnea_weight=training_params['apnea_weight'])\n","train_res = evaluate(model, train_data)\n","test_res = evaluate(model, test_data)\n","print(train_res)\n","print(test_res)\n","utils.save_session(session_name,\n","                   model,\n","                   model_params,\n","                   num_records,\n","                   test_split,\n","                   val_split,\n","                   preprocess_func,\n","                   preprocess_params,\n","                   data_bal,\n","                   data_size,\n","                   training_params,\n","                   optimizer,\n","                   optimizer_params,\n","                   train_res,\n","                   test_res,\n","                   log_dir,\n","                   model_weights_dir,\n","                   res_path = 'results')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Starting Training\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-75ae90881822>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           apnea_weight=training_params['apnea_weight'])\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrain_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Personal Projects/Sleep Apnea Study/apnea-study/lib/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, loss_object, optimizer, log_dir, model_weights_dir, num_epochs, batch_size, apnea_weight)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mapnea_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m def _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs,\n\u001b[0m\u001b[1;32m    117\u001b[0m                        out_grads, skip_input_indices):\n\u001b[1;32m    118\u001b[0m   \"\"\"Calls the gradient function of the op.\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"alhxhJWBcemi","colab_type":"code","colab":{}},"source":["evaluate(model, val_data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F3h9bZkQcenF","colab_type":"text"},"source":["### Evaluation"]},{"cell_type":"code","metadata":{"id":"vB1SjBalcenI","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from lib.utils import to_dense_tensors\n","%matplotlib inline\n","\n","dataset = load_tfrecords(tf_rec_data_dir='data/processed_data')\n","dataset = dataset.map(to_dense_tensors)\n","for dp in dataset:\n","    pass\n","x = dp['x']\n","y = dp['y']\n","plt.plot((x - tf.math.reduce_mean(x)) / tf.math.reduce_std(x))\n","plt.plot(np.repeat(y,16))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ibYiJpiKcenL","colab_type":"code","colab":{}},"source":["pulse_sample_rate = 16\n","data_stride = 30\n","seq_len = 16\n","X = []\n","Y = []\n","#normalize pulse data by night of sleep\n","x = (x - tf.math.reduce_mean(x)) / tf.math.reduce_std(x)\n","#convert night of sleep from 1 dimensional sequence of num samples length\n","#to a sequence of pulse_sample_rate dimension of num seconds length\n","num_seconds = x.shape[0]//pulse_sample_rate\n","x_trunc = x[:pulse_sample_rate*(num_seconds)]\n","x = tf.reshape(x_trunc,[num_seconds,pulse_sample_rate])\n","#create new datapoints, according to data_stride\n","num_data_points = (x.shape[0]//data_stride) - (seq_len//data_stride)\n","for i in range(0,num_data_points):\n","    X.append(x[data_stride*i:data_stride*i+seq_len])\n","    Y.append(y[data_stride*i:data_stride*i+seq_len])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"irEqrQhgcenR","colab_type":"code","colab":{}},"source":["(np.absolute(x[data_stride*i:data_stride*i+seq_len].numpy().flatten()) > 1.5).any()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOIGRHLscenT","colab_type":"code","colab":{}},"source":["type(x[data_stride*i:data_stride*i+seq_len])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oam8U4v1cenW","colab_type":"code","colab":{}},"source":["y[data_stride*i:data_stride*i+seq_len].numpy().mean() == 0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ugIRC6PXcenc","colab_type":"text"},"source":["### ToDo and Scrap"]},{"cell_type":"code","metadata":{"id":"UB6CTnukcene","colab_type":"code","colab":{}},"source":["#fix learning rate\n","#visualize function\n","#develop model search procedure - preprocessing, architecture, training params\n","#set seeds\n","\n","#remove outliers\n","#0-1 scaling \n","\n","\n","#write main.py with argparse\n","#write shell script for parameter tuning\n","#set up interpretion, eda notebook\n","#turn model params into keyword args\n","#add metrics to tensorboard\n","#add keyboard interupt to training loop\n","\n","import pandas as pd\n","import os\n","import re\n","import pickle\n","os.getcwd()\n","results_path = 'results'\n","\n","def get_resuts_df(results_path):\n","    \"\"\"Summarizes session result pickles in a dataframe\n","    \n","    Parameters:\n","    ------------\n","    \n","    results_path (str) : path to session result pickles\n","    \n","    Returns:\n","    ---------\n","    results_df (pd.DataFrame) : results in dataframe format\n","    \n","    \n","    \"\"\"\n","    results_exp = re.compile(r'.*\\.pickle$')\n","    results_list = os.listdir(results_path)\n","    results_list = list(filter(results_exp.search,results_list))\n","    results_df = []\n","    for result_file in results_list:\n","        results_full_path = os.path.join(results_path,result_file)\n","        with open(results_full_path,'rb') as file:\n","            session_results = pickle.load(file)\n","            session_series = pd.Series()\n","            session_series['session_name'] = result_file\n","            for key in session_results:\n","                if isinstance(session_results[key],dict):\n","                    for subkey in session_results[key]:\n","                        session_series[key+'_'+subkey] = session_results[key][subkey]\n","                else:\n","                    session_series[key] = session_results[key]\n","            results_df.append(session_series)\n","    results_df = pd.DataFrame(results_df)\n","    return results_df\n","\n","df = get_resuts_df(results_path)\n","session_cols = ['session_name','data_bal_train','data_bal_test']\n","result_cols = ['train_res_recall','train_res_precision','train_res_f1',\t'train_res_auc',\n","               'test_res_accuracy', 'test_res_recall', 'test_res_precision', 'test_res_f1',\t'test_res_auc']\n","\n","df[session_cols+result_cols]\n"],"execution_count":0,"outputs":[]}]}